{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQFADrpuwxNpdH289cslxG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suruchi-Hardaha/Profanity-Filter-for-kids-using-video-sharing-platform/blob/profanity-filter/profanity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube_transcript_api\n",
        "!pip install youtube-transcript-downloader\n",
        "#!pip install youtube_transcript_api.formatters"
      ],
      "metadata": {
        "id": "HmmoP7FanDVs",
        "outputId": "4d6f9120-afb9-47fe-be5c-03cf0c00c209",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2024.2.2)\n",
            "Installing collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-0.6.2\n",
            "Collecting youtube-transcript-downloader\n",
            "  Downloading youtube_transcript_downloader-0.1.2-py3-none-any.whl (4.5 kB)\n",
            "Installing collected packages: youtube-transcript-downloader\n",
            "Successfully installed youtube-transcript-downloader-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h5W5zRQxN9vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hQdcdkwDN-Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0RIvlA7hN-Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OKonE1m-N-QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0VEcQZEz7FNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r\"/content/requests.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQDE-5PEnDfC",
        "outputId": "aeb5bf3e-bd15-4778-def9-df324a9e24e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r /content/requests.txt (line 1)) (2.31.0)\n",
            "Collecting mock==3.0.5 (from -r /content/requests.txt (line 4))\n",
            "  Downloading mock-3.0.5-py2.py3-none-any.whl (25 kB)\n",
            "Collecting httpretty==1.1.4 (from -r /content/requests.txt (line 5))\n",
            "  Downloading httpretty-1.1.4.tar.gz (442 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.4/442.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coveralls==1.11.1 (from -r /content/requests.txt (line 6))\n",
            "  Downloading coveralls-1.11.1-py2.py3-none-any.whl (12 kB)\n",
            "Collecting coverage==5.2.1 (from -r /content/requests.txt (line 7))\n",
            "  Downloading coverage-5.2.1.tar.gz (694 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m694.1/694.1 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mock==3.0.5->-r /content/requests.txt (line 4)) (1.16.0)\n",
            "Collecting docopt>=0.6.1 (from coveralls==1.11.1->-r /content/requests.txt (line 6))\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/requests.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/requests.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/requests.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/requests.txt (line 1)) (2024.2.2)\n",
            "Building wheels for collected packages: httpretty, coverage, docopt\n",
            "  Building wheel for httpretty (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for httpretty: filename=httpretty-1.1.4-py3-none-any.whl size=28791 sha256=0b63be5776516351b8a2e5746c55b80518b1364decda02fe8b60cb7ac5c34e45\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/84/74/456da302b40f8d81976edc741ba0a04bf64fd4bb3c58aca9fb\n",
            "  Building wheel for coverage (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for coverage: filename=coverage-5.2.1-cp310-cp310-linux_x86_64.whl size=233911 sha256=d74e443093b2da695cae006134d53c9283b8d178b1dbe8499da2e5e056360091\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/ce/76/cb886c97ff226f543bdc5f7bc97d3d7c7aae9f06c1083af3af\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=5b77614820b34b3ce7fe421f6aa3c718cd098411de570d258bf6c53838734b17\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built httpretty coverage docopt\n",
            "Installing collected packages: docopt, mock, httpretty, coverage, coveralls\n",
            "Successfully installed coverage-5.2.1 coveralls-1.11.1 docopt-0.6.2 httpretty-1.1.4 mock-3.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-IqC3lRJ8EIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import TRUE\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from youtube_transcript_api.formatters import TextFormatter\n",
        "import requests\n",
        "import re\n",
        "import os\n",
        "\n",
        "def get_video_id(youtube_url):\n",
        "    \"\"\"\n",
        "    Extract the video ID from a YouTube URL.\n",
        "    Args:\n",
        "        youtube_url (str): The YouTube URL.\n",
        "    Returns:\n",
        "        str: The extracted video ID or None if not found.\n",
        "    \"\"\"\n",
        "    pattern = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
        "    match = re.search(pattern, youtube_url)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "def get_video_title(video_id):\n",
        "    \"\"\"\n",
        "    Get the title of the YouTube video.\n",
        "    Args:\n",
        "        video_id (str): The YouTube video ID.\n",
        "    Returns:\n",
        "        str: The title of the video or \"Unknown\" if not found.\n",
        "    \"\"\"\n",
        "    url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        matches = re.findall(r'<title>(.*?)</title>', response.text)\n",
        "        return matches[0].replace(\" - YouTube\", \"\") if matches else \"Unknown\"\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching video title: {e}\")\n",
        "        return \"Unknown\"\n",
        "\n",
        "def download_transcript(video_id):\n",
        "    \"\"\"\n",
        "    Download the transcript and return as a string.\n",
        "    Args:\n",
        "        video_id (str): The YouTube video ID.\n",
        "    Returns:\n",
        "        str: The transcript text or an empty string if an error occurs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "        transcript = transcript_list.find_generated_transcript(['en'])\n",
        "\n",
        "        formatter = TextFormatter()\n",
        "        transcript_text = formatter.format_transcript(transcript.fetch())\n",
        "\n",
        "        # Remove timecodes and speaker names\n",
        "        transcript_text = re.sub(r'\\[\\d+:\\d+:\\d+\\]', '', transcript_text)\n",
        "        transcript_text = re.sub(r'<\\w+>', '', transcript_text)\n",
        "        return transcript_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading transcript: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def main():\n",
        "    youtube_url = input(\"Enter the YouTube video link: \")\n",
        "    video_id = get_video_id(youtube_url)\n",
        "\n",
        "    if video_id:\n",
        "        transcript_text = download_transcript(video_id)\n",
        "        if transcript_text:\n",
        "            video_title = get_video_title(video_id)\n",
        "            file_name = f\"{video_id}_{video_title}.txt\"\n",
        "            file_name = re.sub(r'[\\\\/*?:\"<>|]', '', file_name)  # Remove invalid characters\n",
        "\n",
        "            with open(file_name, 'w', encoding='utf-8') as file:\n",
        "                file.write(transcript_text)\n",
        "\n",
        "            print(f\"Transcript saved to {file_name}\")\n",
        "        else:\n",
        "            print(\"Unable to download transcript.\")\n",
        "    else:\n",
        "        print(\"Invalid YouTube URL.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYCIo2CH7FYj",
        "outputId": "188e9ee0-5a67-45dc-82a0-4474624934c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the YouTube video link: https://youtu.be/GMA8LR96_T0\n",
            "Transcript saved to GMA8LR96_T0_The UK&#39;s Bizarre Swear Words Officially Ranked!.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "#import json"
      ],
      "metadata": {
        "id": "eODt2afz7Fbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qPxJnqeCOAQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text():\n",
        "    quotes=input(\"enter the filepath: \")\n",
        "    with open(quotes,\"r\")as f:\n",
        "    #quotes = open(\"/content/pMf1LHd8gy4_Be Aware of these SWEAR, NOTORIOUS, BAD &amp; Curse words in English  Vocabulary Lesson for Beginners..txt\")\n",
        "\n",
        "      contents_of_file = f.read()\n",
        "    age=17\n",
        "   # print(contents_of_file)\n",
        "   # quotes.close()\n",
        "\n",
        "    check_profanity(contents_of_file,age)\n",
        "\n",
        "\n",
        "def check_profanity(text_to_check,age):\n",
        "    Word_db = [\"idiot\",\"stupid\",\"shit\",\"\",\"minger\"]\n",
        "    if set(Word_db).intersection(set(text_to_check.split())):\n",
        "        if(age<18):\n",
        "          print(\"The age detected is \" ,age ,\" which is less then 18 and\")\n",
        "          print(\"This contains language not suitable for minors\")\n",
        "        else:\n",
        "          print(\" no curse words found\")\n",
        "read_text()"
      ],
      "metadata": {
        "id": "vLQSoGUZOATw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cedd688-96f8-4b08-f3e1-8693d5c65232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter the filepath: /content/GMA8LR96_T0_The UK&#39;s Bizarre Swear Words Officially Ranked!.txt\n",
            "The age detected is  17  which is less then 18 and\n",
            "This contains language not suitable for minors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OqaDiO1NOAWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ieXoizxVOAZ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}